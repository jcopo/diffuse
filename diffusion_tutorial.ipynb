{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Need to include:\n",
    "  - Short mathemtatical explanation of the diffusion processination of mixtures, closed form mixture when diffused and conditional inverse problems\n",
    "  - Introduction of the different components of the package (SDE, Denoiser, Timer, Integrator) joint with how diffusion models work. Plots to illustrate the components.\n",
    "  - Explain different choice for each component\n",
    "  - Plots to illustrate the diffusion on the mixture example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreword: Gaussian Mixtures\n",
    "\n",
    "## Conditional Gaussian Mixture Models for Diffusion-Based Inverse Problems\n",
    "\n",
    "This module implements Bayesian inference with Gaussian mixture models (GMMs) in the context of diffusion processes and linear inverse problems.\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "### 1. Gaussian Mixture Model (GMM)\n",
    "\n",
    "A GMM represents a probability distribution as a weighted sum of $K$ Gaussian components:\n",
    "\n",
    "$$p(x)=\\sum_{i=1}^Kw_i\\mathcal{N}(x;\\mu_i,\\Sigma_i)$$\n",
    "\n",
    "Where:\n",
    "- $w_i\\geq0$, $\\sum_iw_i=1$ (mixture weights)\n",
    "- $\\mu_i\\in\\mathbb{R}^d$ (component means)\n",
    "- $\\Sigma_i\\in\\mathbb{R}^{d\\times d}$ (component covariance matrices)\n",
    "\n",
    "\n",
    "### 3. Closed-Form Solution for GMM + Diffusion\n",
    "\n",
    "When the prior is a GMM, the diffused distribution remains a GMM:\n",
    "\n",
    "$$p_t(x_t)=\\sum_iw_i\\mathcal{N}(x_t;\\mu_i(t),\\Sigma_i(t))$$\n",
    "\n",
    "Where:\n",
    "- $\\mu_i(t)=\\sqrt{\\alpha(t)}\\mu_i(0)$\n",
    "- $\\Sigma_i(t)=\\alpha(t)\\Sigma_i(0)+(1-\\alpha(t))I$\n",
    "- $w_i(t)=w_i(0)$ (weights unchanged)\n",
    "\n",
    "### 4. Bayesian Posterior with Linear Measurements\n",
    "\n",
    "Given measurement: $y=Ax+\\varepsilon$, where $\\varepsilon\\sim\\mathcal{N}(0,\\sigma_y^2I)$\n",
    "\n",
    "The posterior is also a GMM:\n",
    "\n",
    "$$p(x|y)=\\sum_i\\bar{w}_i\\mathcal{N}(x;\\bar{\\mu}_i,\\bar{\\Sigma})$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{\\Sigma}=\\left(I+\\frac{1}{\\sigma_y^2}A^TA\\right)^{-1}$\n",
    "- $\\bar{\\mu}_i=\\bar{\\Sigma}\\left(\\frac{1}{\\sigma_y^2}A^Ty+\\mu_i\\right)$\n",
    "- $\\bar{w}_i\\propto w_i\\times p(y|\\mu_i)$\n",
    "- $p(y|\\mu_i)=\\mathcal{N}(y;A\\mu_i,\\sigma_y^2I+AA^T)$\n",
    "\n",
    "This conjugacy property makes GMMs particularly useful for diffusion-based inverse problems, as the posterior can be computed analytically at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Diffusion Models\n",
    "\n",
    "Typically, diffusion models can be described by a stochastic differential equation (SDE) of the form:\n",
    "$$dx(t)=f(x, t)dt + g(t)dW(t)$$\n",
    "It corresponds to slowly adding noise to the signal $x(t)$ over time such that the noised signal at time $t$ can be written as:\n",
    "$$p(x(t)|x(0))=\\mathcal{N}(x(t);s(t)x(0), s(t)^2\\sigma(t)^2\\mathbf{I})$$\n",
    "or \n",
    "$$x(t) = s(t)x(0) + s(t)\\sigma(t)\\varepsilon, \\quad \\varepsilon\\sim\\mathcal{N}(0,I)$$\n",
    "\n",
    "$s(t)$ describes how the original data $x(0)$ is attenuated or amplified over time as noise is added while $\\sigma(t)$ it controls how much noise has been injected into the system at that time step. Both are avaible in closed form given $f(x, t)$ and $g(t)$.\n",
    "\n",
    "$$\n",
    "\\boxed{s(t) \\;=\\; \\exp\\!\\left(\\int_0^t f(\\xi)\\, d\\xi\\right),  \\quad\n",
    "\\sigma(t) \\;=\\; \\left(\\int_0^t \\frac{g(\\xi)^2}{s(\\xi)^2}\\, d\\xi \\right)^{1/2}}.\n",
    "$$\n",
    "\n",
    "The previous equation describes a way to add noise to a signal. It is possible to define a time reversed process that describes the denoising of the signal by an backward SDE:\n",
    "\n",
    "$$dx=[f(x,t)âˆ’g(t)^2\\nabla_x\\log p_t(x)]dt+g(t)d\\bar{W}(t)$$\n",
    "\n",
    "### Generative Models\n",
    "In order to generate new samples $x_0$ from pure noise $x_T$, diffusion models leverage the mathematical description of the denoising process defined above. The python class `Denoiser` is used to define the diffusion process starting from noise $x_T$ and denoising until new data $x_0$ is generated. It leverages the class `Integrator` to perform the numerical integration of the backward SDE. Possible choices of `Integrator` are: `EulerIntegrator`, `HeunIntegrator`, `DPMpp2sIntegrator`, `DDIMIntegrator`.\n",
    "\n",
    "Most `Integrator` defined in the litterature necessitate $f$ and $g$ or $s$ and $\\sigma$ to be defined. These attributes are defined in a `DiffusionModel` class.\n",
    "\n",
    "The time discretization used in the `Denoiser` is defined in the `Timer` class. Possible choices of `Timer` are: `LinearTimer` or `CosineTimer`.\n",
    "\n",
    "We also provide a `CondDenoiser` class to sample conditionally on a measurement $y$ to generate samples $x_0 \\sim p(x_0|y)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timer "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
